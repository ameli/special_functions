name: deploy-conda

on:
    # push:
    #     branches:
    #         - main
    release:
        types:
            - published

jobs:
    build_wheels:
        name: Build wheels on ${{ matrix.os }}
        runs-on: ${{ matrix.os }}
        strategy:
            fail-fast: false
            matrix:
                os: [ubuntu-latest, windows-latest, macos-latest]
                
        steps:
            - name: Checkout
              uses: actions/checkout@v4
            
            - name: Setup Python 
              uses: actions/setup-python@v4
              with:
                python-version: '3.12'

              # Without this, installing cuda give error: no much space left on device
            - name: Clear Cache
              if: matrix.os != 'windows-latest'
              run: rm -rf /opt/hostedtoolcache 

            # Build wheel for windows with CUDA enabled. Note that cibuildwheel
            # does not need manylinux docker, thuns, CUDA can be installed in
            # the github action's virtual machine using the Jimver's action
            # in the previous action (see above).
            - name: Build wheels in windows (X86_64)
              if: matrix.os == 'windows-latest'
              uses: pypa/cibuildwheel@v2.15.0
              env:
                  CIBW_ARCHS_WINDOWS: "AMD64 x86"
                  CIBW_BUILD: "*-win_amd64"
                  CIBW_SKIP: "pp* cp36-* cp37-* cp38-*"
                  CIBW_BUILD_VERBOSITY: 1
              with:
                output-dir: wheelhouse

            # Build wheel for windows with CUDA enabled. Note that cibuildwheel
            # does not need manylinux docker, thuns, CUDA can be installed in
            # the github action's virtual machine using the Jimver's action
            # in the previous action (see above).
            - name: Build wheels in windows (ARM64)
              if: matrix.os == 'windows-latest'
              uses: pypa/cibuildwheel@v2.15.0
              env:
                  CIBW_ARCHS_WINDOWS: "ARM64"
                  CIBW_BUILD: "*-win_arm64"
                  CIBW_SKIP: "pp* cp36-* cp37-* cp38-*"
                  CIBW_BUILD_VERBOSITY: 1
              with:
                output-dir: wheelhouse
           
            # Do not enable compiling with CUDA for macos since NIVDIA no
            # longer supports CUDA in the macos.
            - name: Build wheels in mac (X86_64)
              if: matrix.os == 'macos-latest'
              uses: pypa/cibuildwheel@v2.15.0
              env:
                  CIBW_ARCHS_MACOS: "x86_64"
                  CIBW_BUILD: "*-macosx_x86_64"
                  CIBW_SKIP: "pp* cp36-* cp37-* cp38-*"
                  CIBW_BUILD_VERBOSITY: 1
                  CIBW_BEFORE_BUILD: brew reinstall gcc
              with:
                output-dir: wheelhouse

            # Do not enable compiling with CUDA for macos since NIVDIA no
            # longer supports CUDA in the macos.
            # - name: Build wheels in mac (arm64)
            #   if: matrix.os == 'macos-latest'
            #   uses: pypa/cibuildwheel@v2.15.0
            #   env:
            #       CIBW_ARCHS_MACOS: "arm64"
            #       CIBW_BUILD: "*-macosx_arm64"
            #       CIBW_SKIP: "pp* cp36-* cp37-* cp38-*"
            #       CIBW_BUILD_VERBOSITY: 1
            #       CIBW_BEFORE_BUILD: brew reinstall gcc
            #   with:
            #     output-dir: wheelhouse

            # Enable compiling with CUDA, only for linux. Note that cuda must
            # be installed "inside" the manylinux docker image, not in the main
            # github virtual machine. Also, we should use manylinux2014, but
            # not manylinux1. Because of this, we will not install CUDA with
            # the Jimver's action (unlike we did so for the windows wheel in
            # the above). The ``CUDA_DYNAMIC_LOADING=0`` disables dynamic
            # loading of CUDA library. Base of this, when the wheels are
            # created in manylinux platform, the cuda's libraries
            # (libcudart.so, libcublas.so, libcusparse.so) will bundle to
            # the wheel. This is increases the wheel size, bit since the
            # anaconda cloud upload size is 1GB, the large wheel size will not
            # be a problem. The advantage of bundling cuda libraries to the
            # wheel is that the end-user does not have to install cuda toolkit.
            - name: Build wheels in linux (X86_64)
              if: matrix.os == 'ubuntu-latest'
              uses: pypa/cibuildwheel@v2.15.0
              env:
                  CIBW_MANYLINUX_X86_64_IMAGE: manylinux2014
                  CIBW_ARCHS_LINUX: "x86_64"
                  CIBW_BUILD: "*-manylinux_x86_64"
                  CIBW_SKIP: "pp* cp36-* cp37-* cp38-*"
                  CIBW_BUILD_VERBOSITY: 1
                  # CIBW_BEFORE_BUILD_LINUX: yum update; yum install gcc-gfortran openblas-devel.x86_64 lapack-devel.x86_64 -y
              with:
                output-dir: wheelhouse

            # This does not work, the compilation takes several hours, then fails, even without enabling cuda.
            # - name: Build wheels in linux (AARCH64)
            #   if: matrix.os == 'ubuntu-latest'
            #   uses: pypa/cibuildwheel@v2.15.0
            #   env:
            #       CIBW_MANYLINUX_AARCH64_IMAGE: manylinux2014
            #       CIBW_ARCHS_LINUX: "aarch64"
            #       CIBW_BUILD: "*-manylinux_aarch64"
            #       CIBW_SKIP: "pp* cp36-* cp37-* cp38-*"
            #       CIBW_BUILD_VERBOSITY: 1
            #       # CIBW_BEFORE_BUILD_LINUX: yum update; yum install gcc-gfortran openblas-devel.x86_64 lapack-devel.x86_64 -y
            #   with:
            #     output-dir: wheelhouse
            
            - name: Upload artifacts
              uses: actions/upload-artifact@v3
              with:
                  name: wheel-artifacts
                  path: ./wheelhouse/*.whl
                  retention-days: 1

    build_conda:
        needs: [build_wheels]
        name: Build conda on ${{ matrix.os }}
        runs-on: ${{ matrix.os }}
        strategy:
            fail-fast: false
            matrix:
                os: [ubuntu-latest, windows-latest, macos-latest]
        
        # To upload to PyPI on every tag starting with 'v', use the following:
        # if: github.event_name == 'push' && startsWith(github.event.ref, 'refs/tags/v')
        # To publish to pypi on each GitHub Release, use the following:
        # if: github.event_name == 'release' && github.event.action == 'published'
        steps:

            - name: Clean runner space
              if: matrix.os == 'ubuntu-latest'
              run: |
                  sudo rm -rf /usr/share/dotnet
                  sudo rm -rf /opt/ghc
                  sudo rm -rf "/usr/local/share/boost"
                  sudo rm -rf "$AGENT_TOOLSDIRECTORY"
                  docker system prune -af

            - name: Checkout
              uses: actions/checkout@v3

            - name: Download artifacts
              uses: actions/download-artifact@v3
              with:
                  name: wheel-artifacts
                  path: dist

            - name: Setup Miniconda
              uses: conda-incubator/setup-miniconda@v2
              with:
                  miniconda-version: "latest"
                  auto-update-conda: true

            - name: Build and upload package
              shell: bash -el {0}
              run: |
                  conda install -y conda-build anaconda-client
                  conda config --set anaconda_upload yes
                  export PATH=$(conda info --root):$PATH
                  export PATH=$(conda info --root)/bin:$PATH
                  conda-build --output-folder . .
              env:
                  CYTHON_BUILD_IN_SOURCE: '1'  # see setup.py. Avoids a bug when building with multiple python variants
                  ANACONDA_API_TOKEN: ${{ secrets.ANACONDA_TOKEN }}
                 
            # The manylinux wheels (after repaired with auditwheel) are very
            # large in size. It is better to delete them. If we do not delete
            # them, however, they will be deleted after the retention days,
            # which I set to one day.
            - name: Delete artifacts
              uses: geekyeggo/delete-artifact@v1
              with:
                  name: wheel-artifacts

    test_conda:
        needs: [build_conda]
        name: Test on ${{ matrix.os }} and Python ${{ matrix.python-version }}
        runs-on: ${{ matrix.os }}
        strategy:
            fail-fast: false
            matrix:
                os: [ubuntu-latest, windows-latest, macos-latest]
                python-version: ['3.9', '3.10', '3.11', '3.12']

        steps:
            - name: Setup Miniconda
              uses: conda-incubator/setup-miniconda@v2
              with:
                  auto-update-conda: true
                  python-version: ${{ matrix.python-version }}
                  activate-environment: myenv

            - name: Checkout
              uses: actions/checkout@v3

            # Remove MKL as it causes error in initializing libomp. This only happens in MacOS and
            # the conda (but not pip) installation of this package.
            - name: Remove MKL in MacOS
              if: matrix.os == 'macos-latest'
              shell: bash -l {0}
              run: |
                  conda install nomkl
                  conda remove mkl mkl-service || true  # use true since if mkl or mkl-service does not exist, conda throw error and fails the whole runner action to continue

            - name: Test
              shell: bash -l {0}
              run: |
                  mv special_functions special_functions-DoNotImport
                  rm setup.cfg
                  conda install -c s-ameli special_functions -y
                  conda install scipy -y
                  conda install pytest -y
                  pytest
